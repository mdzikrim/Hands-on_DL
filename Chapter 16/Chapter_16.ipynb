{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLlxof/xoA8KwBj2aAoGos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdzikrim/Hands-on_DL/blob/main/Chapter_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1gtgn6UKQhK",
        "outputId": "4b2ec467-26c7-45b6-f4c8-a82b4c4c41fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: BPSE\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "reber_grammar = {\n",
        "    'B': ['T', 'P'],\n",
        "    'T': ['X', 'S'],\n",
        "    'P': ['V', 'S'],\n",
        "    'X': ['X'],\n",
        "    'S': ['E'],\n",
        "    'V': ['V'],\n",
        "    'E': []\n",
        "}\n",
        "\n",
        "def generate_string(grammar, current='B', max_len=20):\n",
        "    if current == 'E' or max_len <= 0:\n",
        "        return 'E' if current == 'E' else ''\n",
        "    next_symbol = random.choice(grammar[current])\n",
        "    return current + generate_string(grammar, next_symbol, max_len - 1)\n",
        "\n",
        "print(\"Sample:\", generate_string(reber_grammar))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate_string(s):\n",
        "    idx = random.randint(0, len(s)-2)\n",
        "    c = random.choice([ch for ch in \"BTPXSV\" if ch != s[idx]])\n",
        "    return s[:idx] + c + s[idx+1:]\n",
        "\n",
        "X, y = [], []\n",
        "for _ in range(5000):\n",
        "    valid = generate_string(reber_grammar)\n",
        "    X.append(valid)\n",
        "    y.append(1)\n",
        "\n",
        "    invalid = mutate_string(valid)\n",
        "    X.append(invalid)\n",
        "    y.append(0)\n",
        "\n",
        "print(X[:5], y[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy4DHpMhKUxe",
        "outputId": "7700f1dc-a82f-4585-8c3f-b6e1b4160c2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BPSE', 'SPSE', 'BPSE', 'PPSE', 'BTSE'] [1, 0, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=20, padding='post')\n"
      ],
      "metadata": {
        "id": "1Sfw1M71KWOp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=8),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "rPvwHSbSKXhk",
        "outputId": "2dbaf3b3-fa19-4866-e07c-ef6bf6f08e10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to float32\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_val = X_val.astype(np.float32)\n",
        "y_train = np.array(y_train).astype(np.float32)\n",
        "y_val = np.array(y_val).astype(np.float32)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kYZW-ZoKY-n",
        "outputId": "0667357f-2861-4028-e9fb-a4dc9a976138"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5094 - loss: 0.6931 - val_accuracy: 0.5885 - val_loss: 0.6885\n",
            "Epoch 2/5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5831 - loss: 0.6680 - val_accuracy: 0.7780 - val_loss: 0.4696\n",
            "Epoch 3/5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7909 - loss: 0.4510 - val_accuracy: 0.9080 - val_loss: 0.2680\n",
            "Epoch 4/5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9250 - loss: 0.2407 - val_accuracy: 0.9370 - val_loss: 0.1983\n",
            "Epoch 5/5\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9395 - loss: 0.2027 - val_accuracy: 0.9370 - val_loss: 0.1948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x783da21aea90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "def random_date():\n",
        "    base = datetime(2019, 1, 1)\n",
        "    delta = timedelta(days=random.randint(0, 364))\n",
        "    return base + delta\n",
        "\n",
        "input_dates, target_dates = [], []\n",
        "for _ in range(10000):\n",
        "    d = random_date()\n",
        "    input_dates.append(d.strftime(\"%Y-%m-%d\"))\n",
        "    target_dates.append(d.strftime(\"%B %d, %Y\"))\n",
        "\n",
        "print(input_dates[:3], target_dates[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zCW1EPxKbg7",
        "outputId": "e048fd45-529e-4213-94b6-b80f74da83fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2019-10-26', '2019-01-28', '2019-03-10'] ['October 26, 2019', 'January 28, 2019', 'March 10, 2019']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use character-level tokenization\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "input_vec = TextVectorization(output_mode=\"int\", output_sequence_length=12)\n",
        "target_vec = TextVectorization(output_mode=\"int\", output_sequence_length=20)\n",
        "\n",
        "input_vec.adapt(input_dates)\n",
        "target_vec.adapt(target_dates)\n",
        "\n",
        "X_enc = input_vec(input_dates)\n",
        "X_dec = target_vec(target_dates)\n"
      ],
      "metadata": {
        "id": "Yn4CApfJKdOa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = tf.keras.layers.Embedding(100, 64)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = tf.keras.layers.LSTM(64, return_state=True)(x)\n",
        "\n",
        "decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = tf.keras.layers.Embedding(100, 64)(decoder_inputs)\n",
        "x = tf.keras.layers.LSTM(64)(x, initial_state=[state_h, state_c])\n",
        "outputs = tf.keras.layers.Dense(100, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "ENyZcRoaKe-1"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}
