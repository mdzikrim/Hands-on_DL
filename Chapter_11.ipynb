{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdzikrim/Hands-on_DL/blob/main/Chapter_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsLMSxBs7qq8",
        "outputId": "b8e3401d-dabe-464f-d3ce-68cd417a3e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "X_train_full, X_test = X_train_full / 255.0, X_test / 255.0\n",
        "y_train_full, y_test = y_train_full.flatten(), y_test.flatten()\n",
        "\n",
        "# Split validation\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__8kt0Nb7wo7",
        "outputId": "3d654f05-97c2-4e03-b2ab-8ef6de6a6a5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - accuracy: 0.2153 - loss: 2.3188 - val_accuracy: 0.3262 - val_loss: 1.8927\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.3354 - loss: 1.8306 - val_accuracy: 0.2968 - val_loss: 1.8596\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.3640 - loss: 1.7673 - val_accuracy: 0.3868 - val_loss: 1.7378\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.3798 - loss: 1.7173 - val_accuracy: 0.3716 - val_loss: 1.7698\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.3963 - loss: 1.6848 - val_accuracy: 0.3584 - val_loss: 1.7835\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.4121 - loss: 1.6403 - val_accuracy: 0.3768 - val_loss: 1.7326\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.4147 - loss: 1.6420 - val_accuracy: 0.4326 - val_loss: 1.6060\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.4294 - loss: 1.6036 - val_accuracy: 0.4162 - val_loss: 1.6503\n",
            "Epoch 9/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.4364 - loss: 1.5838 - val_accuracy: 0.4026 - val_loss: 1.6418\n",
            "Epoch 10/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.3828 - loss: 1.7366 - val_accuracy: 0.2868 - val_loss: 1.9322\n",
            "Epoch 11/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.3352 - loss: 1.7874 - val_accuracy: 0.3652 - val_loss: 1.7224\n",
            "Epoch 12/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.3706 - loss: 1.7210 - val_accuracy: 0.3556 - val_loss: 1.7076\n"
          ]
        }
      ],
      "source": [
        "def build_model():\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=[32, 32, 3]))\n",
        "    for _ in range(20):\n",
        "        model.add(layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvXqPaDJ7x6B",
        "outputId": "e640bcc0-76de-4f0e-eae7-b19792fc1636"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 19ms/step - accuracy: 0.2958 - loss: 1.9637 - val_accuracy: 0.3896 - val_loss: 1.7113\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.3991 - loss: 1.6914 - val_accuracy: 0.4240 - val_loss: 1.6505\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.4224 - loss: 1.6214 - val_accuracy: 0.3936 - val_loss: 1.7853\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.4402 - loss: 1.5775 - val_accuracy: 0.3358 - val_loss: 1.9071\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.4574 - loss: 1.5322 - val_accuracy: 0.4416 - val_loss: 1.5520\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.4734 - loss: 1.4817 - val_accuracy: 0.4068 - val_loss: 1.6819\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.4908 - loss: 1.4466 - val_accuracy: 0.3970 - val_loss: 1.7331\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5016 - loss: 1.4206 - val_accuracy: 0.4416 - val_loss: 1.5939\n",
            "Epoch 9/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5119 - loss: 1.3921 - val_accuracy: 0.4692 - val_loss: 1.4959\n",
            "Epoch 10/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.5200 - loss: 1.3522 - val_accuracy: 0.4894 - val_loss: 1.4786\n",
            "Epoch 11/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.5285 - loss: 1.3384 - val_accuracy: 0.4678 - val_loss: 1.5129\n",
            "Epoch 12/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.5400 - loss: 1.3139 - val_accuracy: 0.4524 - val_loss: 1.6362\n",
            "Epoch 13/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5411 - loss: 1.3018 - val_accuracy: 0.4822 - val_loss: 1.4474\n",
            "Epoch 14/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.5457 - loss: 1.2784 - val_accuracy: 0.4592 - val_loss: 1.5468\n",
            "Epoch 15/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5600 - loss: 1.2533 - val_accuracy: 0.4356 - val_loss: 1.6155\n",
            "Epoch 16/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.5665 - loss: 1.2406 - val_accuracy: 0.4874 - val_loss: 1.4605\n",
            "Epoch 17/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.5738 - loss: 1.2090 - val_accuracy: 0.5094 - val_loss: 1.4096\n",
            "Epoch 18/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.5799 - loss: 1.1911 - val_accuracy: 0.4992 - val_loss: 1.4678\n",
            "Epoch 19/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5844 - loss: 1.1849 - val_accuracy: 0.5012 - val_loss: 1.4053\n",
            "Epoch 20/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5893 - loss: 1.1681 - val_accuracy: 0.5130 - val_loss: 1.3649\n",
            "Epoch 21/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5934 - loss: 1.1613 - val_accuracy: 0.4652 - val_loss: 1.5776\n",
            "Epoch 22/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.6022 - loss: 1.1444 - val_accuracy: 0.4932 - val_loss: 1.5354\n",
            "Epoch 23/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.6058 - loss: 1.1182 - val_accuracy: 0.4960 - val_loss: 1.4854\n",
            "Epoch 24/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.6122 - loss: 1.1026 - val_accuracy: 0.4856 - val_loss: 1.5750\n",
            "Epoch 25/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.6147 - loss: 1.0986 - val_accuracy: 0.4512 - val_loss: 1.6614\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4e6aa26350>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def build_bn_model():\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=[32, 32, 3]))\n",
        "    for _ in range(20):\n",
        "        model.add(layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Activation(\"elu\"))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    return model\n",
        "\n",
        "model_bn = build_bn_model()\n",
        "model_bn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model_bn.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw9XyRHG7ztB",
        "outputId": "28a66340-d6c4-4fff-b9fa-2a72ee048e26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13ms/step - accuracy: 0.1915 - loss: 2.1791 - val_accuracy: 0.2550 - val_loss: 1.9771\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.2751 - loss: 1.9326 - val_accuracy: 0.2900 - val_loss: 1.8643\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.2967 - loss: 1.8816 - val_accuracy: 0.3198 - val_loss: 1.8771\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.3059 - loss: 1.8556 - val_accuracy: 0.3230 - val_loss: 1.7955\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.3354 - loss: 1.7915 - val_accuracy: 0.3542 - val_loss: 1.7953\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.3485 - loss: 1.7597 - val_accuracy: 0.3518 - val_loss: 1.7634\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.3591 - loss: 1.7369 - val_accuracy: 0.3608 - val_loss: 1.7869\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.3746 - loss: 1.7077 - val_accuracy: 0.3294 - val_loss: 1.9011\n",
            "Epoch 9/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.3727 - loss: 1.7085 - val_accuracy: 0.3852 - val_loss: 1.7004\n",
            "Epoch 10/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.3891 - loss: 1.6766 - val_accuracy: 0.3682 - val_loss: 1.7076\n",
            "Epoch 11/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.4022 - loss: 1.6431 - val_accuracy: 0.3636 - val_loss: 1.7738\n",
            "Epoch 12/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.3709 - loss: 1.7725 - val_accuracy: 0.2480 - val_loss: 1.9167\n",
            "Epoch 13/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.2675 - loss: 1.8879 - val_accuracy: 0.2856 - val_loss: 1.8572\n",
            "Epoch 14/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.2917 - loss: 1.8219 - val_accuracy: 0.2502 - val_loss: 1.9753\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4e65de76d0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def build_selu_model():\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=[32, 32, 3]))\n",
        "    for _ in range(20):\n",
        "        model.add(layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    return model\n",
        "\n",
        "model_selu = build_selu_model()\n",
        "model_selu.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model_selu.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1MBQ5th72gO",
        "outputId": "be212cab-fb68-4323-b9c9-c2a0db732296"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 0.1017 - loss: 2.4656 - val_accuracy: 0.1010 - val_loss: 6.9263\n",
            "Epoch 2/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.1451 - loss: 2.2147 - val_accuracy: 0.0996 - val_loss: 2.7365\n",
            "Epoch 3/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.1729 - loss: 2.1081 - val_accuracy: 0.1528 - val_loss: 2.2214\n",
            "Epoch 4/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.1825 - loss: 2.0806 - val_accuracy: 0.1550 - val_loss: 2.3790\n",
            "Epoch 5/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - accuracy: 0.1828 - loss: 2.0675 - val_accuracy: 0.1650 - val_loss: 2.3152\n",
            "Epoch 6/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1881 - loss: 2.0437 - val_accuracy: 0.1064 - val_loss: 2.8123\n",
            "Epoch 7/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.1820 - loss: 2.0723 - val_accuracy: 0.1178 - val_loss: 2.5916\n",
            "Epoch 8/30\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.1994 - loss: 2.0212 - val_accuracy: 0.1400 - val_loss: 2.4031\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4e66086350>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MCDropout(layers.Dropout):\n",
        "    def call(self, inputs, training=None):\n",
        "        return super().call(inputs, training=True)  # aktif saat inference juga\n",
        "\n",
        "def build_mc_model():\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=[32, 32, 3]))\n",
        "    for _ in range(20):\n",
        "        model.add(layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "        model.add(layers.AlphaDropout(rate=0.1))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    return model\n",
        "\n",
        "model_mc = build_mc_model()\n",
        "model_mc.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model_mc.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7X2Z1Ii75dz",
        "outputId": "40e2db46-9674-4c6e-bd79-9af340ddfbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 21ms/step - accuracy: 0.2596 - loss: 2.0783 - val_accuracy: 0.2428 - val_loss: 2.5525\n",
            "Epoch 2/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.3457 - loss: 1.8238 - val_accuracy: 0.3234 - val_loss: 2.0072\n",
            "Epoch 3/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.4136 - loss: 1.6426 - val_accuracy: 0.4528 - val_loss: 1.5363\n",
            "Epoch 4/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.4325 - loss: 1.5905 - val_accuracy: 0.3402 - val_loss: 2.1324\n",
            "Epoch 5/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.4044 - loss: 1.6781 - val_accuracy: 0.4008 - val_loss: 1.6481\n",
            "Epoch 6/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.4564 - loss: 1.5077 - val_accuracy: 0.4668 - val_loss: 1.5070\n",
            "Epoch 7/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.4587 - loss: 1.5117 - val_accuracy: 0.3382 - val_loss: 2.0230\n",
            "Epoch 8/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.4419 - loss: 1.5708 - val_accuracy: 0.4564 - val_loss: 1.5214\n",
            "Epoch 9/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.5039 - loss: 1.4048 - val_accuracy: 0.4486 - val_loss: 1.6664\n",
            "Epoch 10/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.4890 - loss: 1.4286 - val_accuracy: 0.3804 - val_loss: 1.9426\n",
            "Epoch 11/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.4842 - loss: 1.4485 - val_accuracy: 0.4596 - val_loss: 1.5026\n",
            "Epoch 12/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.5402 - loss: 1.2909 - val_accuracy: 0.4816 - val_loss: 1.4805\n",
            "Epoch 13/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.5160 - loss: 1.3562 - val_accuracy: 0.4012 - val_loss: 1.7347\n",
            "Epoch 14/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 21ms/step - accuracy: 0.5209 - loss: 1.3563 - val_accuracy: 0.5274 - val_loss: 1.3371\n",
            "Epoch 15/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - accuracy: 0.5681 - loss: 1.2069 - val_accuracy: 0.4420 - val_loss: 1.5839\n",
            "Epoch 16/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.5341 - loss: 1.3110 - val_accuracy: 0.4478 - val_loss: 1.5912\n",
            "Epoch 17/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.5580 - loss: 1.2594 - val_accuracy: 0.5578 - val_loss: 1.2679\n",
            "Epoch 18/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.5935 - loss: 1.1516 - val_accuracy: 0.4084 - val_loss: 1.7712\n",
            "Epoch 19/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.5506 - loss: 1.2623 - val_accuracy: 0.3882 - val_loss: 1.8422\n",
            "Epoch 20/20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 25ms/step - accuracy: 0.5783 - loss: 1.1981 - val_accuracy: 0.5596 - val_loss: 1.2751\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4e633a3dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "class LCycle(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, base_lr=1e-5, max_lr=1e-2, step_size=2000):\n",
        "        super().__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.iterations = 0\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
        "        self.iterations += 1\n",
        "        self.model.optimizer.learning_rate.assign(lr)\n",
        "\n",
        "model_cycle = build_bn_model()\n",
        "model_cycle.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Nadam(), metrics=[\"accuracy\"])\n",
        "\n",
        "lcycle = LCycle()\n",
        "model_cycle.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[lcycle, early_stop])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1YiT63Y3PWV7zeyE1Lucz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}